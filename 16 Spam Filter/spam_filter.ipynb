{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Spam Filter with Naive Bayes\n",
    "\n",
    "This project is part of guided projects available on [Dataquest.io](https://dataquest.io). The aim of this project is to use naive Bayes algorithm to mark SMS messages as spam or not spam. The dataset was put together by Tiago A. Almeida and José María Gómez Hidalgo, and it can be downloaded from the [The UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/sms+spam+collection). Data collection process can be found following [this link](https://www.dt.fee.unicamp.br/~tiago/smsspamcollection/#composition).\n",
    "\n",
    "There are two colums in the dataset. First marking the message as:\n",
    "- `ham` – no spam\n",
    "- `spam` - spam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Exploring the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening the SMS Spam Collection .csv file\n",
    "sms_spam = pd.read_csv(\"SMSSpamCollection.csv\", sep=\"\\t\", header=None, names=[\"label\", \"SMS\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5572 entries, 0 to 5571\n",
      "Data columns (total 2 columns):\n",
      "label    5572 non-null object\n",
      "SMS      5572 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 87.2+ KB\n",
      "None\n",
      "\n",
      "\n",
      "  label                                                SMS\n",
      "0   ham  Go until jurong point, crazy.. Available only ...\n",
      "1   ham                      Ok lar... Joking wif u oni...\n",
      "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3   ham  U dun say so early hor... U c already then say...\n",
      "4   ham  Nah I don't think he goes to usf, he lives aro...\n"
     ]
    }
   ],
   "source": [
    "# exploring the dataset\n",
    "print(sms_spam.info())\n",
    "print(\"\\n\")\n",
    "print(sms_spam.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     86.593683\n",
       "spam    13.406317\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms_spam[\"label\"].value_counts(normalize=True) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains two colums and 5572 rows, all non-null values. 13% of the messages are marked as spam.\n",
    "\n",
    "## 2. Training and Test Set\n",
    "To test the spam filter, we're first going to split our dataset into two categories **training set** and **testing set.** We're going to keep 80% of our dataset for training, and 20% for testing (we want to train the algorithm on as much data as possible, but we also want to have enough test data).\n",
    "\n",
    "|Set    |No. Messages|Percentage|\n",
    "|:------| ----------:|---------:|\n",
    "|Trainig| 4,458      | 80 %     |\n",
    "|Testing| 1,114      | 20 %     |\n",
    "\n",
    "For this project, our goal is to create a spam filter that classifies new messages with an accuracy greater than 80% — so we expect that more than 80% of the new messages will be classified correctly as spam or ham (non-spam).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4458, 2)\n",
      "(1114, 2)\n"
     ]
    }
   ],
   "source": [
    "# randomizing the entire dataset\n",
    "sms_random = sms_spam.sample(frac=1, random_state=1)\n",
    "\n",
    "# spliting the datset into train and test\n",
    "train = sms_random.iloc[0:4458].reset_index(drop=True)\n",
    "test = sms_random.iloc[4458:].reset_index(drop=True)\n",
    "\n",
    "# checking the leng of bot sets\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ham     86.54105\n",
      "spam    13.45895\n",
      "Name: label, dtype: float64\n",
      "\n",
      "\n",
      "ham     86.804309\n",
      "spam    13.195691\n",
      "Name: label, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# checking the spam percentage in bot sets - should resemble the original\n",
    "print(train[\"label\"].value_counts(normalize=True) * 100)\n",
    "print(\"\\n\")\n",
    "print(test[\"label\"].value_counts(normalize=True) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both training and test set have similar spam and not spam messages ratio. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Cleaning\n",
    "To calculate probabilities that a unique word might be potentially spammy (words like money, win, secret), we first need to perform a bit of data cleaning to bring the data in a format that will allow us to extract easily all the information we need. Right now, our training and test sets have this format (simplifeid):\n",
    "\n",
    "|index|label|sms                                     |\n",
    "|:---:|----:| -------:                               |\n",
    "| 0   |spam | SECRET PRIZE! CLAIM SECRET PRIZE NOW!! |\n",
    "| 1   | ham | Comming to my secret party?            |\n",
    "| 2   |spam | Winner! Claim secret prize now         |\n",
    "\n",
    "To make the calculations easier, we want bring the data to this format (the table below is a transformation of the table you see above):\n",
    "\n",
    "\n",
    "|index|label|secret|prize|claim|now|comming|to|my|party|winner|\n",
    "|:---:|----:|-----:|-----:|-----:|---:|-------:|---:|----:|----:|---:|\n",
    "|0|spam|2|2|1|1|0|0|0|0|0|\n",
    "|1|ham|1|0|0|0|1|1|1|1|0|\n",
    "|2|spam|1|1|1|1|0|0|0|0|1|\n",
    "\n",
    "About the transformation above, notice that:\n",
    "\n",
    "- The `SMS` column doesn't exist anymore.\n",
    "- Instead, the `SMS` column is replaced by a series of new columns, where each column represents a unique word from the vocabulary.\n",
    "- Each row describes a single message. For instance, the first row corresponds to the message *\"SECRET PRIZE! CLAIM SECRET PRIZE NOW!!\",* and it has the values `spam, 2, 2, 1, 1, 0, 0, 0, 0, 0`. These values tell us that:\n",
    "    - The message is spam.\n",
    "    - The word \"secret\" occurs two times inside the message.\n",
    "    - The word \"prize\" occurs two times inside the message.\n",
    "    - The word \"claim\" occurs one time inside the message.\n",
    "    - The word \"now\" occurs one time inside the message.\n",
    "    - The words \"coming\", \"to\", \"my\", \"party\", and \"winner\" occur zero times inside the message.\n",
    "- All words in the vocabulary are in lower case, so \"SECRET\" and \"secret\" come to be considered to be the same word.\n",
    "- Punctuation is not taken into account anymore (for instance, we can't look at the table and conclude that the first message initially had three exclamation marks)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>ham</td>\n",
       "      <td>Yep, by the pretty sculpture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ham</td>\n",
       "      <td>Yes, princess. Are you going to make me moan?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>ham</td>\n",
       "      <td>Welp apparently he retired</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>ham</td>\n",
       "      <td>Havent.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>ham</td>\n",
       "      <td>I forgot 2 ask ü all smth.. There's a card on ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                                SMS\n",
       "0   ham                       Yep, by the pretty sculpture\n",
       "1   ham      Yes, princess. Are you going to make me moan?\n",
       "2   ham                         Welp apparently he retired\n",
       "3   ham                                            Havent.\n",
       "4   ham  I forgot 2 ask ü all smth.. There's a card on ..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training set before cleaning\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>ham</td>\n",
       "      <td>yep  by the pretty sculpture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ham</td>\n",
       "      <td>yes  princess  are you going to make me moan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>ham</td>\n",
       "      <td>welp apparently he retired</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>ham</td>\n",
       "      <td>havent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>ham</td>\n",
       "      <td>i forgot 2 ask ü all smth   there s a card on ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                                SMS\n",
       "0   ham                       yep  by the pretty sculpture\n",
       "1   ham      yes  princess  are you going to make me moan \n",
       "2   ham                         welp apparently he retired\n",
       "3   ham                                            havent \n",
       "4   ham  i forgot 2 ask ü all smth   there s a card on ..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# removing non aA-zZ and 0-9 characters\n",
    "train[\"SMS\"] = train[\"SMS\"].str.replace(\"\\W\", \" \",)\n",
    "\n",
    "# lowering all charasters\n",
    "train[\"SMS\"] = train[\"SMS\"].str.lower()\n",
    "\n",
    "# training set after cleaning\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Creating the Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7783"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# empty vocabulary list\n",
    "vocabulary = []\n",
    "\n",
    "# transforming each message into list of words\n",
    "train[\"SMS\"] = train[\"SMS\"].str.split()\n",
    "\n",
    "# iterating over the SMS column and appending unique words to vocublary list\n",
    "for message in train[\"SMS\"]:\n",
    "    for word in message:\n",
    "        vocabulary.append(word)\n",
    "\n",
    "# transforming vocabulary into set, removing duplicates and back to a list\n",
    "vocabulary = list(set(vocabulary))\n",
    "\n",
    "# lenght of the vocabulary list\n",
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the train set we have now a list of 7,783 unique words.\n",
    "\n",
    "#### 3.3 Final Training Set\n",
    "Let's now move to creating the vocabulary, which in this context means a list with all the unique words in our training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts_per_sms = {unique_word: [0] * len(train[\"SMS\"]) for unique_word in vocabulary}\n",
    "\n",
    "for index, sms in enumerate(train[\"SMS\"]):\n",
    "    for word in sms:\n",
    "        word_counts_per_sms[word][index] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spoken</th>\n",
       "      <th>4get</th>\n",
       "      <th>fundamentals</th>\n",
       "      <th>may</th>\n",
       "      <th>w1</th>\n",
       "      <th>pie</th>\n",
       "      <th>nickey</th>\n",
       "      <th>done</th>\n",
       "      <th>mad</th>\n",
       "      <th>no</th>\n",
       "      <th>...</th>\n",
       "      <th>1x150p</th>\n",
       "      <th>bcz</th>\n",
       "      <th>gods</th>\n",
       "      <th>tue</th>\n",
       "      <th>5k</th>\n",
       "      <th>gower</th>\n",
       "      <th>skills</th>\n",
       "      <th>1mega</th>\n",
       "      <th>2wt</th>\n",
       "      <th>anjie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7783 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   spoken  4get  fundamentals  may  w1  pie  nickey  done  mad  no  ...  \\\n",
       "0       0     0             0    0   0    0       0     0    0   0  ...   \n",
       "1       0     0             0    0   0    0       0     0    0   0  ...   \n",
       "2       0     0             0    0   0    0       0     0    0   0  ...   \n",
       "3       0     0             0    0   0    0       0     0    0   0  ...   \n",
       "4       0     0             0    0   0    0       0     0    0   0  ...   \n",
       "\n",
       "   1x150p  bcz  gods  tue  5k  gower  skills  1mega  2wt  anjie  \n",
       "0       0    0     0    0   0      0       0      0    0      0  \n",
       "1       0    0     0    0   0      0       0      0    0      0  \n",
       "2       0    0     0    0   0      0       0      0    0      0  \n",
       "3       0    0     0    0   0      0       0      0    0      0  \n",
       "4       0    0     0    0   0      0       0      0    0      0  \n",
       "\n",
       "[5 rows x 7783 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transforming the word counts per sms to dataframe\n",
    "word_counts = pd.DataFrame(word_counts_per_sms)\n",
    "word_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>spoken</th>\n",
       "      <th>4get</th>\n",
       "      <th>fundamentals</th>\n",
       "      <th>may</th>\n",
       "      <th>w1</th>\n",
       "      <th>pie</th>\n",
       "      <th>nickey</th>\n",
       "      <th>done</th>\n",
       "      <th>...</th>\n",
       "      <th>1x150p</th>\n",
       "      <th>bcz</th>\n",
       "      <th>gods</th>\n",
       "      <th>tue</th>\n",
       "      <th>5k</th>\n",
       "      <th>gower</th>\n",
       "      <th>skills</th>\n",
       "      <th>1mega</th>\n",
       "      <th>2wt</th>\n",
       "      <th>anjie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>ham</td>\n",
       "      <td>[yep, by, the, pretty, sculpture]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ham</td>\n",
       "      <td>[yes, princess, are, you, going, to, make, me,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>ham</td>\n",
       "      <td>[welp, apparently, he, retired]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>ham</td>\n",
       "      <td>[havent]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>ham</td>\n",
       "      <td>[i, forgot, 2, ask, ü, all, smth, there, s, a,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                                SMS  spoken  4get  \\\n",
       "0   ham                  [yep, by, the, pretty, sculpture]       0     0   \n",
       "1   ham  [yes, princess, are, you, going, to, make, me,...       0     0   \n",
       "2   ham                    [welp, apparently, he, retired]       0     0   \n",
       "3   ham                                           [havent]       0     0   \n",
       "4   ham  [i, forgot, 2, ask, ü, all, smth, there, s, a,...       0     0   \n",
       "\n",
       "   fundamentals  may  w1  pie  nickey  done  ...  1x150p  bcz  gods  tue  5k  \\\n",
       "0             0    0   0    0       0     0  ...       0    0     0    0   0   \n",
       "1             0    0   0    0       0     0  ...       0    0     0    0   0   \n",
       "2             0    0   0    0       0     0  ...       0    0     0    0   0   \n",
       "3             0    0   0    0       0     0  ...       0    0     0    0   0   \n",
       "4             0    0   0    0       0     0  ...       0    0     0    0   0   \n",
       "\n",
       "   gower  skills  1mega  2wt  anjie  \n",
       "0      0       0      0    0      0  \n",
       "1      0       0      0    0      0  \n",
       "2      0       0      0    0      0  \n",
       "3      0       0      0    0      0  \n",
       "4      0       0      0    0      0  \n",
       "\n",
       "[5 rows x 7785 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combining the training set with the table above\n",
    "train_clean = pd.concat([train, word_counts], axis=1)\n",
    "train_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Calculating Constant First\n",
    "\n",
    "To calculate the Naive Bayes algorithm will need to know the probability values of the two equations below to be able to classify new messages:\n",
    "\n",
    "- P(*Spam* | *w<sub>1</sub>, w<sub>2</sub>,..., w<sub>n</sub>*) ∝ *P(Spam)* ⋅ ∏<sup>n</sup> <sub>i=1</sub> *P(w<sub>i</sub> | Spam)*\n",
    "- P(*Ham* | *w<sub>1</sub>, w<sub>2</sub>,..., w<sub>n</sub>*) ∝ *P(Ham)* ⋅ ∏<sup>n</sup> <sub>i=1</sub> *P(w<sub>i</sub> | Ham)*\n",
    "\n",
    "Also, to calculate P(w<sub>i</sub> | Spam) and P(w<sub>i</sub> | Ham) inside the formulas above, we need to use these equations:\n",
    "\n",
    "- P(w<sub>i</sub> | Spam) = (*N<sub>wi | Spam</sub> + α*) / (*N<sub>Spam</sub> + α ⋅ N<sub>Vocabulary</sub>*)\n",
    "- P(w<sub>i</sub> | Ham) = (*N<sub>wi | Ham</sub> + α*) / (*N<sub>Ham</sub> + α ⋅ N<sub>Vocabulary</sub>*)\n",
    "\n",
    "Let's first calculate:\n",
    "- P(Spam) and P(Ham)\n",
    "- N<sub>Spam</sub>, N<sub>Ham</sub>, N<sub>Vocabulary</sub>\n",
    "\n",
    "To use Laplace smoothing we'll set α = 1.\n",
    "\n",
    "### 4.1 P(Spam) and P(Ham)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# isolating spam messages and ham messages\n",
    "spam = train_clean[train_clean[\"label\"] == \"spam\"]\n",
    "ham = train_clean[train_clean[\"label\"] == \"ham\"]\n",
    "\n",
    "# calculating probabilities of spam and ham\n",
    "p_spam = len(spam) / len(train_clean)\n",
    "p_ham = len(ham) / len(train_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 N<sub>Spam</sub>, N<sub>Ham</sub> and N<sub>Vocabulary</sub>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of words in spam messages\n",
    "n_words_per_spam_message = spam[\"SMS\"].apply(len)\n",
    "n_spam = n_words_per_spam_message.sum()\n",
    "\n",
    "# number of words in ham messages\n",
    "n_words_per_ham_message = ham[\"SMS\"].apply(len)\n",
    "n_ham = n_words_per_ham_message.sum()\n",
    "\n",
    "# number of words in vocabulary messages\n",
    "n_vocabulary = len(vocabulary)\n",
    "\n",
    "# alpha variable\n",
    "alpha = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Calculating Parametres\n",
    "We have 7,783 words in our `vocabulary`, which means we'll need to calculate a total of 15,566 probabilities. For each word, we need to calculate both P(w<sub>i</sub> | Spam) and P(w<sub>i</sub> | Ham)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing dictionary for each word in voacabulary for spam and ham\n",
    "spam_dic = {unique_word:0 for unique_word in vocabulary}\n",
    "ham_dic = {unique_word:0 for unique_word in vocabulary}\n",
    "\n",
    "# calculating the probabilites for each word\n",
    "for word in vocabulary:\n",
    "    n_word_given_spam = spam[word].sum()\n",
    "    p_word_given_spam = (n_word_given_spam + alpha) / (n_spam + alpha * n_vocabulary)\n",
    "    spam_dic[word] = p_word_given_spam\n",
    "\n",
    "    n_word_given_ham = ham[word].sum()\n",
    "    p_word_given_ham = (n_word_given_ham + alpha) / (n_ham + alpha * n_vocabulary)\n",
    "    ham_dic[word] = p_word_given_ham\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Classifing New Messages\n",
    "All the preparation for creating the spam filter are done and now let's create a function that will:\n",
    "- take as an input new message\n",
    "- Compares the values of P(Spam|w<sub>1</sub>, w<sub>2</sub>, ..., w<sub>n</sub>) and P(Ham|w<sub>1</sub>, w<sub>2</sub>, ..., w<sub>n</sub>), and:\n",
    "    - If P(Ham|w<sub>1</sub>, w<sub>2</sub>, ..., w<sub>n</sub>) > P(Spam|w<sub>1</sub>, w<sub>2</sub>, ..., w<sub>n</sub>), then the message is classified as ham.\n",
    "    - If P(Ham|w<sub>1</sub>, w<sub>2</sub>, ..., w<sub>n</sub>) < P(Spam|w<sub>1</sub>, w<sub>2</sub>, ..., w<sub>n</sub>), then the message is classified as spam.\n",
    "    - If P(Ham|w<sub>1</sub>, w<sub>2</sub>, ..., w<sub>n</sub>) = P(Spam|w<sub>1</sub>, w<sub>2</sub>, ..., w<sub>n</sub>), then the algorithm may request human help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(message):\n",
    "\n",
    "    message = re.sub(\"\\W\", \" \", message)    # cleaning the input message\n",
    "    message = message.lower()\n",
    "    message = message.split()\n",
    "    \n",
    "    p_spam_given_message = p_spam           # initial probability value set as the train dataset probability\n",
    "    p_ham_given_message = p_ham\n",
    "\n",
    "    for word in message:                   # fininding word in both dictionaries\n",
    "        if word in spam_dic:\n",
    "            p_spam_given_message *= spam_dic[word]   # multiplying the word probabilities to get the final probability\n",
    "            \n",
    "        if word in ham_dic:\n",
    "            p_ham_given_message *= ham_dic[word]\n",
    "        # ignoring words that are not part of the vocabulary\n",
    "\n",
    "    print(\"P(Spam|message):\", p_spam_given_message)\n",
    "    print(\"P(Ham|message):\", p_ham_given_message)\n",
    "\n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        print(\"Label: Ham\")\n",
    "    elif p_ham_given_message < p_spam_given_message:\n",
    "        print(\"Label: Spam\")\n",
    "    else:\n",
    "        print(\"Equal proabilities, have a human classify this!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Initial Spam Filter Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing messages\n",
    "test_spam_message = \"WINNER!! This is the secret code to unlock the money: C3421.\"\n",
    "test_ham_message = \"Sounds good, Tom, then see u there\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Spam|message): 1.3481290211300841e-25\n",
      "P(Ham|message): 1.9368049028589875e-27\n",
      "Label: Spam\n"
     ]
    }
   ],
   "source": [
    "# classifing test spam message\n",
    "classify(test_spam_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Spam|message): 2.4372375665888117e-25\n",
      "P(Ham|message): 3.687530435009238e-21\n",
      "Label: Ham\n"
     ]
    }
   ],
   "source": [
    "# clasifing test ham message\n",
    "classify(test_ham_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Measuring Spam Filter Accuracy\n",
    "We we aiming for 80% spam filter accurancy. To see whether we've achieved that let's test our spam filter in the testing set of 1,114 messages. To achieve 80% accurancy we need to correctly mark 891 messages. To mark the messages correctly we will slighlty adjust the `classify` function so it labels the messages rather than printing the outcome. We then need to add the prediction the testing set as a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjusting the classify function\n",
    "def classify_test_set(message):\n",
    "\n",
    "    message = re.sub(\"\\W\", \" \", message)\n",
    "    message = message.lower()\n",
    "    message = message.split()\n",
    "    \n",
    "    p_spam_given_message = p_spam\n",
    "    p_ham_given_message = p_ham\n",
    "\n",
    "    for word in message:\n",
    "        if word in spam_dic:\n",
    "            p_spam_given_message *= spam_dic[word]\n",
    "            \n",
    "        if word in ham_dic:\n",
    "            p_ham_given_message *= ham_dic[word]\n",
    "\n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        return \"ham\"\n",
    "    elif p_ham_given_message < p_spam_given_message:\n",
    "        return \"spam\"\n",
    "    else:\n",
    "        return \"human\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>ham</td>\n",
       "      <td>Later i guess. I needa do mcat study too.</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ham</td>\n",
       "      <td>But i haf enuff space got like 4 mb...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 10 mths? Update to latest Oran...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>ham</td>\n",
       "      <td>All sounds good. Fingers . Makes it difficult ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>ham</td>\n",
       "      <td>All done, all handed in. Don't know if mega sh...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                                SMS prediction\n",
       "0   ham          Later i guess. I needa do mcat study too.        ham\n",
       "1   ham             But i haf enuff space got like 4 mb...        ham\n",
       "2  spam  Had your mobile 10 mths? Update to latest Oran...       spam\n",
       "3   ham  All sounds good. Fingers . Makes it difficult ...        ham\n",
       "4   ham  All done, all handed in. Don't know if mega sh...        ham"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using the function to create new column in the test set\n",
    "test[\"prediction\"] = test[\"SMS\"].apply(classify_test_set)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 Accurancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct:  1100\n",
      "Incorect: 14\n",
      "Total: 1114\n",
      "Accurancy:  98.74 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = len(test)\n",
    "\n",
    "for row in test.iterrows():\n",
    "    row = row[1]\n",
    "    if row[\"label\"] == row[\"prediction\"]:\n",
    "        correct += 1\n",
    "\n",
    "print(\"Correct: \", correct)\n",
    "print(\"Incorect:\", total - correct)\n",
    "print(\"Total:\", total)\n",
    "print(\"Accurancy: \", round((correct/total) * 100, 2), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Spam filter we've build has 98.74 % accurancy. The filter looked at 1,114 messages and marked 1,100 correctly."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
